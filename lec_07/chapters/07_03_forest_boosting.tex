% !TEX root = ../om_ts_06.tex

\begin{frame} % название фрагмента

  \videotitle{Случайный лес и градиентный бустинг}
  
  \end{frame}
  
  
  
  \begin{frame}{Случайный лес и градиентный бустинг: план}
    \begin{itemize}[<+->]
      \item Деревья для случайного леса.
      \item Деревья для градиентного бустинга.
    \end{itemize}
  
  \end{frame}
  

  \begin{frame}
    \frametitle{Случайный лес}

    Особенности деревьев:
    \begin{itemize}[<+->]
      \item Деревьев очень \alert{много}, $n_{tree} = 10000$.
      \item Деревья очень \alert{ветвистые}.
      \item Деревья равноправные: лес \alert{усредняет} прогнозы деревьев.  
    \end{itemize}
  \end{frame}

  \begin{frame}
    \frametitle{Почему деревья разные?}

      Два источника \alert{случайности}:
      \begin{itemize}[<+->]
        \item Каждое дерево растёт случайно. 
        
        Каждое дерево в \alert{каждом своём узле} из большого исходного списка предикторов 
        \alert{удаляет} случайным образом часть предикторов перед поиском оптимального деления. 

        \item Каждое дерево растёт на своей бутстрапированной выборке. 
        
        Из исходных $T$ наблюдений перед построением дерева создаётся новая \alert{искусственная выборка с возвращением} 
        в $T$ наблюдений. 
      \end{itemize}
  \end{frame}

\begin{frame}
  \frametitle{Лес в формулах}
  Построение \alert{деревьев}:
  \begin{itemize}[<+->]
    \item Из $(y, X)$ случайно создаём первую бутстрэп выборку $(y_{BS}^{(1)}, X_{BS}^{(1)})$.
    
    Первое дерево $T_1$ учится прогнозировать $y_{BS}^{(1)}$ с помощью $X_{BS}^{(1)})$.

    \item Из $(y, X)$ случайно создаём вторую бутстрэп выборку $(y_{BS}^{(2)}, X_{BS}^{(2)})$.
    
    Второе дерево $T_2$ учится прогнозировать $y_{BS}^{(2)}$ с помощью $X_{BS}^{(2)})$.

    \item \ldots

  \end{itemize}

  \pause
  Построение \alert{прогнозов}:
  \[
  \text{Forest}(x) = \frac{1}{n_{tree}}(T_1(x) + T_2(x) + \ldots + T_{n_{tree}} (x))
  \]
\end{frame}


  \begin{frame}
    \frametitle{Градиентный бустинг}

    Особенности деревьев:
    \begin{itemize}[<+->]
      \item Деревьев относительно \alert{мало}, вполне возможно, $n_{tree} = 1000$.
      \item Деревья не очень \alert{ветвистые}.
      \item Каждое последующее дерево \alert{уточняет} суммарный прогноз предыдущих деревьев
      с весом $\eta$.
    \end{itemize}
  \end{frame}


  \begin{frame}
    \frametitle{Бустинг в формулах}
    Построение \alert{деревьев}:
    \begin{itemize}[<+->]
      \item Без деревьев прогноз тривиален: 
      \[
        GB_0(x) = \bar y = \frac{y_1 + y_2 + \ldots + y_T}{T}
      \]
      \item Первое дерево $T_1$ учится прогнозировать $r_0 = y - GB_0(X)$ с помощью $X$.
      \item Составляем композитный прогноз:
      \[
      GB_1(x) = GB_0(x) + \eta T_1(x).  
      \]
  
      \item Второе дерево $T_2$ учится прогнозировать $r_1 = y - GB_1(X)$ с помощью  $X$.
      \item Составляем композитный прогноз:
      \[
      GB_2(x) = GB_1(x) + \eta T_2(x).  
      \]
      \item \ldots
  
    \end{itemize}
  
    \pause
    Построение \alert{прогнозов}:
    \[
    GB(x) = \bar y + \eta (T_1(x) + T_2(x) + \ldots + T_{n_{tree}}(x)).
    \]
  \end{frame}
  


  \begin{frame}{Случайный лес и градиентный бустинг: итоги}
  
    \begin{itemize}[<+->]
      \item У алгоритмов \alert{куча вариаций}.
      \item В лесу много \alert{равноправных деревьев} и они \alert{ветвистые}.
      \item В градиентном бустинге деревьев мало, они \alert{небольшие} и каждое последующее дерево \alert{уточняет} прогнозы. 
      \item Для случайного леса стоит взять \alert{побольше деревьев}. 
      \item В градиентном бустинге важен баланс \alert{числа деревьев} и \alert{темпа обучения}. 
    \end{itemize}
  \end{frame}
  
  
  
  