% !TEX root = ../om_ts_06.tex

\begin{frame} % название фрагмента

  \videotitle{Случайный лес и градиентный бустинг}
  
  \end{frame}
  
  
  
  \begin{frame}{Случайный лес и градиентный бустинг: план}
    \begin{itemize}[<+->]
      \item Деревья для \alert{случайного леса}.
      \item Деревья для \alert{градиентного бустинга}.
    \end{itemize}
  
  \end{frame}
  

  \begin{frame}
    \frametitle{Случайный лес}

    Особенности деревьев:
    \begin{itemize}[<+->]
      \item Деревьев очень \alert{много}, $n_{tree} = 10000$.
      \item Деревья очень \alert{ветвистые}.
      \item Деревья равноправные: лес \alert{усредняет} прогнозы деревьев.  
    \end{itemize}
  \end{frame}

  \begin{frame}
    \frametitle{Почему деревья разные?}

      Два источника \alert{случайности}:
      \begin{itemize}[<+->]
        \item Каждое дерево растёт случайно. 
        
        Каждое дерево в \alert{каждом своём узле} из большого исходного списка предикторов 
        \alert{удаляет} случайным образом часть предикторов перед поиском оптимального деления. 

        \item Каждое дерево растёт на своей бутстрэп выборке. 
        
        Из исходных $T$ наблюдений перед построением дерева создаётся новая \alert{искусственная выборка с возвращением} 
        в $T$ наблюдений. 
      \end{itemize}
  \end{frame}


\begin{frame}
  \frametitle{Бутстрэп выборка}
  \alert{Исходная} выборка:
  \[
  y = \begin{pmatrix}
    y_1 \\
    y_2 \\
    y_3 \\
    y_4 \\
    y_5 \\
  \end{pmatrix}  \quad 
  X = \begin{pmatrix}
    a_1 & b_1 \\
    a_2 & b_2 \\
    a_3 & b_3 \\
    a_4 & b_4 \\
    a_5 & b_5 \\
  \end{pmatrix}
  \]
  \pause
  Пример \alert{бутстрэп} выборки:
  \[
  y^* = \begin{pmatrix}
    y_4 \\
    y_2 \\
    y_1 \\
    y_4 \\
    y_1 \\
  \end{pmatrix}  \quad 
  X^* = \begin{pmatrix}
    a_4 & b_4 \\
    a_2 & b_2 \\
    a_1 & b_1 \\
    a_4 & b_4 \\
    a_1 & b_1 \\
  \end{pmatrix}
  \]

\end{frame}


\begin{frame}
  \frametitle{Лес в формулах}
  Построение \alert{деревьев}:
  \begin{itemize}[<+->]
    \item Из $(y, X)$ случайно создаём первую бутстрэп выборку $(y^*, X^*)$.
    
    Первое дерево $T_1$ учится прогнозировать $y^{*}$ с помощью $X^{*}$.

    \item Из $(y, X)$ случайно создаём вторую бутстрэп выборку $(y^*, X^*)$.
    
    Второе дерево $T_2$ учится прогнозировать $y^{*}$ с помощью $X^{*}$.

    \item \ldots

  \end{itemize}

  \pause
  Построение \alert{прогнозов}:
  \[
  \text{Forest}(x) = \frac{1}{n_{tree}}(T_1(x) + T_2(x) + \ldots + T_{n_{tree}} (x))
  \]
\end{frame}


  \begin{frame}
    \frametitle{Градиентный бустинг}

    Особенности деревьев:
    \begin{itemize}[<+->]
      \item Деревьев относительно \alert{мало}, вполне возможно, $n_{tree} = 1000$.
      \item Деревья не очень \alert{ветвистые}.
      \item Каждое последующее дерево \alert{уточняет} суммарный прогноз предыдущих деревьев
      с весом $\eta$.
    \end{itemize}
  \end{frame}


  \begin{frame}
    \frametitle{Бустинг в формулах}
    Построение \alert{деревьев} и прогнозов:
    \begin{itemize}[<+->]
      \item Без деревьев прогноз тривиален: 
      \[
        GB_0(x) = \bar y = \frac{y_1 + y_2 + \ldots + y_T}{T}
      \]
      \item Первое дерево $T_1$ учится прогнозировать $r_0 = y - GB_0(X)$ с помощью $X$.
      \item Составляем композитный прогноз:
      \[
      GB_1(x) = GB_0(x) + \eta T_1(x) =\bar y + \eta T_1(x).  
      \]
  
      \item Второе дерево $T_2$ учится прогнозировать $r_1 = y - GB_1(X)$ с помощью  $X$.
      \item Составляем композитный прогноз:
      \[
      GB_2(x) = GB_1(x) + \eta T_2(x) =\bar y + \eta (T_1(x) + T_2(x)).  
      \]
      \item \ldots
  
    \end{itemize}
  \end{frame}

  
  \begin{frame}
    \frametitle{Как сравнить алгоритмы?}

    \begin{itemize}[<+->]
      \item Нельзя применять критерий Акаике $AIC$. 
      \item Можно применять \alert{кросс-валидацию}! 
      
      Можно даже применять \alert{кросс-валидацию} для \alert{перекрестных данных}!
    \end{itemize}
    
  
  \end{frame}



  \begin{frame}{Случайный лес и градиентный бустинг: итоги}
  
    \begin{itemize}[<+->]
      \item У алгоритмов \alert{куча вариаций}.
      \item В лесу много \alert{равноправных деревьев} и они \alert{ветвистые}.
      \item В градиентном бустинге деревьев мало, они \alert{небольшие} и каждое последующее дерево \alert{уточняет} прогнозы. 
      \item Для случайного леса стоит взять \alert{побольше деревьев}. 
      \item В градиентном бустинге важен баланс \alert{числа деревьев} и \alert{темпа обучения}. 
    \end{itemize}
  \end{frame}
  
  
  
  