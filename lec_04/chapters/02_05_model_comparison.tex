% !TEX root = ../om_ts_02.tex

\begin{frame} % название фрагмента

\videotitle{Сравнение моделей}

\end{frame}



\begin{frame}{Сравнение моделей: план}
  \begin{itemize}[<+->]
    \item MAE и ещё куча страшных слов. 
    \item Кросс-валидация.
    \item Критерий Акаике.
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Помните о цели!}

  Если цель построения модели — прогнозы на один шаг вперёд, 
  то разумно сравнивать модели по прогнозной силе на один шаг вперёд. 

  \pause
  Если цель — обнаружить момент разладки,
  то разумно искать модель дающую минимальную ошибку, когда нет разладки, 
  и максимальную ошибку, когда разладка есть. 

\end{frame}

\begin{frame}
    \frametitle{Обозначения для краткости}

    Для прогноза важно, \alert{когда} его строят, и на \alert{сколько шагов вперёд}:
    \[
    \hat y_{t+h \mid t}.    
    \]

    \pause 
    Иногда для \alert{краткости}:
    \[
    \hat y_{t+h}    
    \]
    \pause 
    Проблемка:
    \[
    \hat y_{(t+1) + 2} \neq \hat y_{(t+2) + 1}.    
    \]    
    
\end{frame}


\begin{frame}
    \frametitle{Показатели антикачества}

    \alert{Ошибка прогноза}: $e_{t+h} = y_{t+h} - \hat y_{t+h}$.

    \pause
    \alert{Средняя абсолютная ошибка} (Mean Absolute Error):
    \[
    MAE = \frac{\abs {e_{T+1}} + \abs{e_{T+1}}+ \ldots + \abs{e_{T+H}} }{H}.
    \]
    \pause
    \alert{Средняя квадратичная ошибка} (Root Mean Squared Error):
    \[
        RMSE = \sqrt{ \frac{e^2_{T+1} + e^2_{T+1}+ \ldots + e^2_{T+H} }{H} }.
    \]
    
\end{frame}


\begin{frame}
    \frametitle{Масштабируем}

    Переводим ошибку $e_{t+h} = y_{t+h} - \hat y_{t+h}$  \alert{в проценты} $p_t= e_t/y_t \cdot 100$ или
    $p^s_t = e_t/(0.5 y_t + 0.5\hat y_t) \cdot 100$.

    \pause
    \alert{Средняя абсолютная процентная ошибка} (Mean Absolute Persentage Error):
    \[
    MAPE = \frac{\abs {p_{T+1}} + \abs{p_{T+1}}+ \ldots + \abs{p_{T+H}} }{H}.
    \]
    \pause 
    \alert{Симметричная средняя абсолютная процентная ошибка} (Symmetric Mean Absolute Persentage Error):
    \[
    sMAPE = \frac{\abs {p^s_{T+1}} + \abs{p^s_{T+1}}+ \ldots + \abs{p^s_{T+H}} }{H}.
    \]
    
\end{frame}

\begin{frame}
    \frametitle{Автоматически сравниваем с наивной}

    \alert{Наивный прогноз}: $\hat y^{naive}_t = y_{t-1}$ или $\hat y^{naive}_t = y_{t-12}$.
    \pause
    Отмасштабируем ошибку нашего прогноза $e_t$ к $MAE^{naive}$:
    \[
    q_t = \frac{e_t}{MAE^{naive}}.
    \]

    \pause
    \alert{Средняя абсолютная отмасштабированная ошибка} (Mean Absolute Scaled Error):
    \[
    MASE  = \frac{\abs {q_{T+1}} + \abs{q_{T+1}}+ \ldots + \abs{q_{T+H}} }{H}.
    \]

    \pause 
    Сравнение $q$ с единицей сравнивает нашу модель с наивной. 


\end{frame}


\begin{frame}
    \frametitle{Обучающая и тестовая выборка}

    Стратегия: 
    \begin{enumerate}[<+->]
        \item Делим всю выборку на \alert{обучающую} (в начале) и \alert{тестовую} (в конце).
        \item \alert{Оцениваем} несколько моделей по обучающей выборке.
        \item \alert{Прогнозируем} каждое наблюдение тестовой выборки с помощью каждой модели.
        \item Рассчитываем \alert{ошибки} прогнозов моделей.  
        \item \alert{Сравниваем} модели по $MAE$ и выбираем лучшую.
    \end{enumerate}

    \pause
    Недостаток: \alert{у прогнозов разный горизонт}.

\end{frame}


\begin{frame}
    \frametitle{Деление на обучающую и тестовую}

    картинка с растущими стрелочками-параболками

\end{frame}


\begin{frame}
    \frametitle{Кросс-валидация скользящим окном}

    Стратегия:
    \begin{enumerate}[<+->]
        \item Выбираем стартовый размер \alert{обучающей} выборки (в начале).
        \item \alert{Оцениваем} несколько моделей по обучающей выборке.
        \item \alert{Прогнозируем} на один шаг вперёд с помощью каждой модели. 
        \item Рассчитываем \alert{ошибки} прогнозов моделей.  
        \item \alert{Сдвигаем} обучающую выборку на одно наблюдение вправо. 
        \item Повторяем шаги 2-5.
        \item \alert{Сравниваем} модели по $MAE$ и выбираем лучшую.
    \end{enumerate}

\end{frame}


\begin{frame}
    \frametitle{Кросс-валидация скользящим окном}

    картинка с растущими стрелочками-параболками

\end{frame}



\begin{frame}
    \frametitle{Кросс-валидация растущим окном}

    Стратегия:
    \begin{enumerate}
        \item Выбираем стартовый размер обучающей выборки (в начале).
        \item Оцениваем несколько моделей по обучающей выборке.
        \item Прогнозируем на один шаг вперёд с помощью каждой модели. 
        \item Рассчитываем ошибки прогнозов моделей.  
        \item \alert{Увеличиваем} обучающую выборку на одно наблюдение. 
        \item Повторяем шаги 2-5.
        \item Сравниваем модели по $MAE$ и выбираем лучшую.
    \end{enumerate}

\end{frame}


\begin{frame}
    \frametitle{Кросс-валидация растущим окном}

    картинка с растущими стрелочками-параболками

\end{frame}


\begin{frame}
    \frametitle{Кросс-валидация: обсуждение}

    Кросс-валидация \alert{скользящим} окном: наблюдений много и мы подозреваем, что 
    зависимость изменяется.
    \pause
    Кросс-валидация \alert{растущим} окном: наблюдений мало или мы уверены 
    в том, что зависимость сохраняется.
    \pause
    Кросс-валидация — может быть долгой!

\end{frame}

\begin{frame}
    \frametitle{Сделаем кросс-валидацию по-быстрому!}

    Примерная замена кросс-валидации на один шаг вперёд по $RMSE$.

    \alert{Критерий Акаике} (Akaike Information Criterion):
    \pause
    \[
      AIC = -2 \ln L + 2k,
    \]
    гда $\ln L$ — логарифм максимума правдоподобия на обучающей выборке, $k$ — общее число параметров модели. 
    
\end{frame}

\begin{frame}
    \frametitle{Нюансы $AIC$}

    \begin{itemize}[<+->]
        \item $AIC$ имеет \alert{теоретические основания}:
        \[
            \frac{AIC_A - AIC_B}{2} \approx KL(\text{Truth} || \text{Model A}) - KL(\text{Truth} || \text{Model B}).
        \]
        \item Может использоваться \alert{для невложенных моделей}. 
        \item Для гауссовских моделей $y_t$ критерий аппроксимирует \alert{сравнение по $RMSE$}.
        \item Сравниваемые модели должны моделировать \alert{те же} наблюдения. 
        \item Разный софт может исключать из правдоподобия \alert{разные константы}. 
    \end{itemize}

    

\end{frame}


\begin{frame}{Сравнение моделей: итоги}

  \begin{itemize}[<+->]
    \item MAE, RMSE, MAPE, MASE.
    \item Кросс-валидация: скользящее и растущее окно.
    \item AIC — быстрый примерный аналог кросс-валидации. 
  \end{itemize}
\end{frame}



